{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqpmTS8DzVLIfJW8KJJ+0s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","\n","# Load the ClinicalBERT tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n","model = AutoModelForTokenClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=3)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5R6vjNQbODq","executionInfo":{"status":"ok","timestamp":1679291850023,"user_tz":-330,"elapsed":1129,"user":{"displayName":"Ashik Nizar","userId":"03772746786185557958"}},"outputId":"45ca3303-6237-4027-e36a-45ed58c1d567"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Define example clinical text\n","text = \"The patient was diagnosed with diabetes and hypertension.\"\n","\n","# Tokenize the text and convert to input format\n","tokens = tokenizer.tokenize(text)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","input_ids = torch.tensor([token_ids])\n","attention_mask = torch.tensor([[1] * len(token_ids)])\n","inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n","\n","\n"],"metadata":{"id":"vPlZG08dlsIx","executionInfo":{"status":"ok","timestamp":1679291850025,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ashik Nizar","userId":"03772746786185557958"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Pass the input through the model and get the predicted labels\n","outputs = model(**inputs)\n","predicted_labels = torch.argmax(outputs.logits, axis=2)[0]\n","\n","# Map the predicted labels back to the original tokenization and extract entities\n","entities = []\n","entity_labels = []\n","current_entity = \"\"\n","current_label = None\n","for i, label in enumerate(predicted_labels):\n","    if label == 1:\n","        if current_entity:\n","            entities.append(current_entity)\n","            entity_labels.append(current_label)\n","            current_entity = \"\"\n","            current_label = None\n","        current_entity = tokens[i]\n","        current_label = label\n","    elif i > 0 and label == 2 and predicted_labels[i-1] == 1:\n","        current_entity += f\" {tokens[i]}\"\n","    elif label == 2:\n","        if current_entity:\n","            entities.append(current_entity)\n","            entity_labels.append(current_label)\n","            current_entity = \"\"\n","            current_label = None\n","\n"],"metadata":{"id":"fm9c4FpdlyPm","executionInfo":{"status":"ok","timestamp":1679291850623,"user_tz":-330,"elapsed":608,"user":{"displayName":"Ashik Nizar","userId":"03772746786185557958"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# If an entity is still being processed at the end of the text, append it\n","if current_entity:\n","    entities.append(current_entity)\n","    entity_labels.append(current_label)\n","\n","# Print the predicted entities and their labels\n","for entity, label in zip(entities, entity_labels):\n","    print(f\"{entity}: {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-uSyf2sl2r1","executionInfo":{"status":"ok","timestamp":1679291864426,"user_tz":-330,"elapsed":419,"user":{"displayName":"Ashik Nizar","userId":"03772746786185557958"}},"outputId":"480cd919-a03e-4182-ca54-a55a75b073ed"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["the: 1\n","patient: 1\n","was: 1\n","with: 1\n","and: 1\n","##tens: 1\n","##ion: 1\n","##ion: 1\n"]}]}]}